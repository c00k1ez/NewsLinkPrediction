experiment_name: softmax_loss_long_bert_grad_accum

backbone_model: BertModel
freeze_backbone: true
main_model: SiameseNetwork

model:
  encoder_hidden: 768
  output_dim: 256
  n_chunks: 4
  chunk_size: 512

criterion_name: SoftmaxLoss

optimizer:
  lr: 5e-5
  weight_decay: 1e-5

scheduler:
  num_warmup_steps: 500

datasets:
  news_pad_len: 512
  broadcast_pad_len: 2048

loaders:
  batch_size: 350 # for 16gb Tesla P100

trainer:
  accumulate_grad_batches: 2
  max_epochs: 20